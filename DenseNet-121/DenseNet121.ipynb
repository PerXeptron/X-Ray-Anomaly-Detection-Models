{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DenseNet121.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V45LHACzJxGi",
        "colab_type": "text"
      },
      "source": [
        "## Mount Drive and Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0P7x_4ULHbr_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "09f62261-7e3e-4660-ba5c-475eaac90a5f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_2Ll8meIBKw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ce5abcc1-8dd1-4a03-b947-98ebb8de22e8"
      },
      "source": [
        "!unzip -uq '/content/gdrive/My Drive/chexpertdataset.zip'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "error:  zipfile read error\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ps-jyezTKZkC",
        "colab_type": "text"
      },
      "source": [
        "## Import Basic Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtfiz4KMIF81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYo5P1rgKe5N",
        "colab_type": "text"
      },
      "source": [
        "## Read and clean the  DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "du1b0of2IL6m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "outputId": "43ec1ce5-6edc-4939-e9b1-e092f3054af3"
      },
      "source": [
        "df = pd.read_csv('CheXpert-v1.0-small/train.csv') # Earlier, df_train\n",
        "df_val = pd.read_csv('CheXpert-v1.0-small/valid.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-1f24a6be12d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CheXpert-v1.0-small/train.csv'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Earlier, df_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CheXpert-v1.0-small/valid.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File CheXpert-v1.0-small/train.csv does not exist: 'CheXpert-v1.0-small/train.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLx4C5qXJ0_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_df(df):\n",
        "  # Focusing only on 5 classes:\n",
        "  df = df[[\n",
        "    'Path', \n",
        "    'Atelectasis',\n",
        "    'Cardiomegaly',\n",
        "    'Consolidation',\n",
        "    'Edema',\n",
        "    'Pleural Effusion'\n",
        "  ]]\n",
        "\n",
        "  # Handling the NaN values\n",
        "  df = df.fillna(0)\n",
        "\n",
        "  # Handling the uncertain values\n",
        "  ## Different policy for each feature:\n",
        "  u_ones = ['Atelectasis', 'Edema']\n",
        "  u_zeros = ['Cardiomegaly', 'Consolidation', 'Pleural Effusion']\n",
        "  df[u_ones]  = df[u_ones].replace(-1, 1)\n",
        "  df[u_zeros] = df[u_zeros].replace(-1, 0)\n",
        "\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jd4QXLd8IO9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df[[\n",
        "  'Path', \n",
        "  'Atelectasis',\n",
        "  'Cardiomegaly',\n",
        "  'Consolidation',\n",
        "  'Edema',\n",
        "  'Pleural Effusion'\n",
        "]]\n",
        "\n",
        "# Handling the NaN values\n",
        "df = df.fillna(0)\n",
        "\n",
        "# Handling the uncertain values\n",
        "## Different policy for each feature:\n",
        "u_ones = ['Atelectasis', 'Edema']\n",
        "u_zeros = ['Cardiomegaly', 'Consolidation', 'Pleural Effusion']\n",
        "df[u_ones]  = df[u_ones].replace(-1, 1)\n",
        "df[u_zeros] = df[u_zeros].replace(-1, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71vrB_-lJ7JX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = clean_df(df)\n",
        "df_val = clean_df(df_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psjtHtTSKkUg",
        "colab_type": "text"
      },
      "source": [
        "## Set a few constants and to-be-used Class names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fihb_ZPwIRnM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "IMAGE_SIZE = 224\n",
        "CLASSES = [ \n",
        "  'Atelectasis',\n",
        "  'Cardiomegaly',\n",
        "  'Consolidation',\n",
        "  'Edema',\n",
        "  'Pleural Effusion'\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKOTlwhsIfFm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FRAC = 0.003 # Fraction of total data to be taken as sample\n",
        "SHAPE = (320, 390, 3) # Common shape for featurewise centering & normalization\n",
        "\n",
        "sample_paths = df['Path'].sample(frac=FRAC).to_numpy()\n",
        "X_temp = np.array([np.array(cv2.imread(path, 1), dtype=float) for path in sample_paths])\n",
        "X_sample = np.array([x for x in X_temp if x.shape == SHAPE])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sZkamIiKtAk",
        "colab_type": "text"
      },
      "source": [
        "## A custon preprocessing function to experiment with\n",
        "\n",
        "We tried histogram equalization to mimic deeper constrasts in the image, but unfortunately, it didn't return results as we had expected, so we dropped this in the end."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6F-v478nfKxm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def image_preprocess(img):\n",
        "  img = cv2.convertScaleAbs(img)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  dst = cv2.equalizeHist(img)\n",
        "  dst = cv2.cvtColor(dst, cv2.COLOR_GRAY2RGB)\n",
        "  dst = dst.astype(np.float64)\n",
        "  return dst"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oV9--WjVNHoT",
        "colab_type": "text"
      },
      "source": [
        "## Set up Image Data Generator for Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isOE73_YIpI-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator as IDG\n",
        "\n",
        "datagen = IDG(\n",
        "    rescale=1./255, \n",
        "    featurewise_center=True,\n",
        "    featurewise_std_normalization=True,\n",
        "    rotation_range=0.1,\n",
        "    zoom_range = 0.1,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split = 0.1,\n",
        "    fill_mode = 'nearest',\n",
        ")\n",
        "\n",
        "datagen.fit(X_sample)\n",
        "\n",
        "test_datagen = IDG(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C53TZWrAIsDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_gen():\n",
        "  train_gen = datagen.flow_from_dataframe(\n",
        "      dataframe = df,\n",
        "      #directory = '/content/CheXpert-v1.0-small/train',\n",
        "      x_col = 'Path',\n",
        "      y_col = CLASSES, #'classes',\n",
        "      class_mode='raw',\n",
        "      #validate_filenames = False,\n",
        "      seed=42,\n",
        "      shuffle=True,\n",
        "      target_size=(IMAGE_SIZE, IMAGE_SIZE), \n",
        "      batch_size=BATCH_SIZE, \n",
        "      subset = 'training'\n",
        "  )\n",
        "\n",
        "  val_gen = datagen.flow_from_dataframe(\n",
        "      dataframe = df,\n",
        "      #directory = '/content/CheXpert-v1.0-small/train',\n",
        "      x_col = 'Path',\n",
        "      y_col = CLASSES, #'classes',\n",
        "      class_mode='raw',\n",
        "      #validate_filenames = False,\n",
        "      seed=42,\n",
        "      shuffle=True,\n",
        "      target_size=(IMAGE_SIZE, IMAGE_SIZE), \n",
        "      batch_size=BATCH_SIZE, \n",
        "      #classes = columns,\n",
        "      subset = 'validation'\n",
        "  )\n",
        "\n",
        "  return train_gen, val_gen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtdurrZ8NPSi",
        "colab_type": "text"
      },
      "source": [
        "## Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYyWvcJjI2pj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Building on top of the base:\n",
        "from keras.applications import DenseNet121\n",
        "from keras.models import Sequential\n",
        "from keras.layers import BatchNormalization, Conv2D, GlobalAveragePooling2D\n",
        "from keras.layers.core import Flatten, Dense, Dropout\n",
        "\n",
        "def build_model():\n",
        "  # The convolutional base:\n",
        "  model_base = DenseNet121(\n",
        "      weights='imagenet', include_top=False, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)\n",
        "      )\n",
        "  #model_base.trainable = False\n",
        "  # Unfreezing all the layers:\n",
        "  for layer in model_base.layers:\n",
        "      layer.trainable = True\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(model_base) # Adding the base as a layer\n",
        "  model.add(GlobalAveragePooling2D())\n",
        "  model.add(Dense(1024, activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.3))\n",
        "  #model.add(Flatten())\n",
        "  #model.add(Dense(1024, activation='relu'))\n",
        "  #model.add(Dropout(0.25))\n",
        "  model.add(Dense(5, activation='sigmoid'))\n",
        "  \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1ETpsqjJWLB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.metrics import AUC, categorical_accuracy as catacc\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "auc = AUC()\n",
        "adam = Adam(learning_rate=0.0001) # 0.05 of default\n",
        "\n",
        "es = EarlyStopping(monitor='val_categorical_accuracy', mode='max', verbose=1, patience=2)\n",
        "mc = ModelCheckpoint(\n",
        "    filepath='densenet121-keras-2.h5', verbose=1 #, save_best_only=True\n",
        ")\n",
        "\n",
        "cb_list = [es, mc] # Will add clr later, as we'll have to tune it's hyperparameters\n",
        "\n",
        "model = build_model()\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=adam,\n",
        "    metrics=[auc, catacc] # Earlier, 'acc' \n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDe4VJEiNU1J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "b7482725-045d-470b-aee4-9e190afc2a2a"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "densenet121 (Model)          (None, 7, 7, 1024)        7037504   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 5)                 5125      \n",
            "=================================================================\n",
            "Total params: 8,096,325\n",
            "Trainable params: 8,010,629\n",
            "Non-trainable params: 85,696\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LriJldfIKlRf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "10385280-deef-4632-abdb-a6788e13b1dd"
      },
      "source": [
        "train_gen, val_gen = get_gen()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 201073 validated image filenames.\n",
            "Found 22341 validated image filenames.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l65tytBsQnvx",
        "colab_type": "text"
      },
      "source": [
        "Set train_steps, validation_steps and number of epochs and let the training begin !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yzklBXCJYgo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training constants:\n",
        "TRAIN_STEPS = train_gen.n//BATCH_SIZE\n",
        "VAL_STEPS   = val_gen.n//BATCH_SIZE\n",
        "N_EPOCHS = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fivmIamUNtL9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9830c8d3-89e8-4b5f-8ab3-b12628675824"
      },
      "source": [
        "TRAIN_STEPS"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6283"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlh96xbRJgJ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "286d03ef-9a6e-4df6-fd7a-6fd8528e2a9a"
      },
      "source": [
        "history = model.fit_generator(\n",
        "    train_gen,\n",
        "    steps_per_epoch=TRAIN_STEPS,\n",
        "    epochs=N_EPOCHS,\n",
        "    validation_data=val_gen,\n",
        "    validation_steps=VAL_STEPS,\n",
        "    callbacks = cb_list\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "6283/6283 [==============================] - 10204s 2s/step - loss: 0.4503 - auc_2: 0.7944 - categorical_accuracy: 0.3677 - val_loss: 0.4274 - val_auc_2: 0.8405 - val_categorical_accuracy: 0.4243\n",
            "\n",
            "Epoch 00001: saving model to densenet121-keras-2.h5\n",
            "Epoch 2/5\n",
            "6283/6283 [==============================] - 10124s 2s/step - loss: 0.4083 - auc_2: 0.8326 - categorical_accuracy: 0.4105 - val_loss: 0.3972 - val_auc_2: 0.8427 - val_categorical_accuracy: 0.4377\n",
            "\n",
            "Epoch 00002: saving model to densenet121-keras-2.h5\n",
            "Epoch 3/5\n",
            "6283/6283 [==============================] - 10158s 2s/step - loss: 0.3985 - auc_2: 0.8411 - categorical_accuracy: 0.4167 - val_loss: 0.4028 - val_auc_2: 0.8273 - val_categorical_accuracy: 0.3504\n",
            "\n",
            "Epoch 00003: saving model to densenet121-keras-2.h5\n",
            "Epoch 4/5\n",
            "2625/6283 [===========>..................] - ETA: 1:33:53 - loss: 0.3948 - auc_2: 0.8443 - categorical_accuracy: 0.4207"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yyun8p45SVsC",
        "colab_type": "text"
      },
      "source": [
        "Google Colab Runtime limitations :(\n",
        "\n",
        "  ## Create test generator and plot ROCAUCs for our model !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMnqRcNMLFap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_gen = test_datagen.flow_from_dataframe(\n",
        "    dataframe = df_val,\n",
        "    #directory = '/content/CheXpert-v1.0-small/valid',\n",
        "    x_col = 'Path',\n",
        "    y_col = CLASSES, #'classes',\n",
        "    class_mode='raw',\n",
        "    #validate_filenames = False,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE), \n",
        "    batch_size=1, \n",
        "    shuffle = False,\n",
        "    #classes = columns,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvr6i_PxMxSK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_labels = df_val[CLASSES].to_numpy()\n",
        "y_pred = model.predict_generator(test_gen, steps=test_gen.n) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OTCkP1hM2_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import auc\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "\n",
        "for i in range(len(CLASSES)):\n",
        "   fpr, tpr, thresholds = roc_curve(y_labels[:, i], y_pred[:, i])\n",
        "   individual_auc = auc(fpr, tpr)\n",
        "   plt.plot(fpr, tpr, label= (CLASSES[i] + '(area = {})'.format(individual_auc)))\n",
        "\n",
        "    \n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('ROC curve')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEwbA0tHV1U2",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://i.ibb.co/jbXfhPs/densenet121-rescale.png)"
      ]
    }
  ]
}